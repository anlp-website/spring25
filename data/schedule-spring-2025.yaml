---
tableRows:
  - 1:
    Week: 1
    Dates: "1/06 - 1/10"
    Topics:
      - "Course introduction"
      - "Text data preprocessing: Normalization, lemmatization, stemming, stop words removal... "
      - "Text Representations: "
      - "One hot encoding"
      - "BoW (frequency counting)"
      - "TF-IDF"
    Quizzes: "Quiz 0 | Knowledge-based | out 1/06 - due 1/10"
    Readings:
      - "Chapter 1 Introduction to Natural Language Processing by Jacob Eisenstein"
      - "Chapter 2.1 Introduction to Natural Language Processing by Jacob Eisenstein"  

  - 2:
    Week: 2
    Dates: "1/13 - 1/17"
    Topics:
      - "Classification Introduction"
      - "Naive Bayes"
      - "Classification Model Evaluation: accuracy, precision, recall, confusion matrix"

    Homework:
      - "HW1 out 1/17"
    Quizzes: "Quiz 1 | week 1| out 1/10 - due 1/17"
    Readings:
      - "Chapter 2.2 Introduction to Natural Language Processing by Jacob Eisenstein"  


  - 3:
    Week: 3
    Dates: "1/20 - 1/24"
    Topics:
      - MLK Official Institute Holiday
      - "Focus on HW1"

  - 4:
    Week: 4
    Dates: "1/27 - 1/31"
    Topics:
      - "Logistic Regression"
      - "SVM"
      - "Perceptron"
    Quizzes: "Quiz 2 | week 2| out 1/24 - due 1/31"
    Readings:
      - "Chapters 2.3, 2.4, 2.5 Introduction to Natural Language Processing by Jacob Eisenstein."
    Homework:
      - "**HW1 due 1/31**"
      - "HW2 out 1/31"

  - 5:
    Week: 5
    Dates: "2/03 - 2/07"
    Topics:
      - SVD (Dimensionality Reduction) + Co-occurrence embeddings
      - Glove
    Quizzes: "Quiz 3 | week 4| out 1/31 - due 2/07"
    Readings:
      - "[GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)"


  - 6:
    Week: 6
    Dates: "2/10 - 2/14"
    Topics:
      - "Neural Network (fully connected)"
      - "Word2vec: CBoW, Skip-Gram"
    Readings:
      - "[NN Playground](https://playground.tensorflow.org/)"
      - "[Interactive NN initialization](https://www.deeplearning.ai/ai-notes/initialization/);"
      - "[The role of a hidden layer](https://www.quora.com/What-is-the-role-of-a-hidden-layer);"
      - "[Back propagation numerical example](https://hmkcode.github.io/ai/backpropagation-step-by-step/);"
      - "[More detailed introduction](/other/nn-intro.pdf);"
      - "[Efficient Estimation of Word Representations in Vector Space](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwid2L-eu4WAAxUPAjQIHds5CocQFnoECA8QAQ&url=https%3A%2F%2Farxiv.org%2Fabs%2F1301.3781&usg=AOvVaw2oae2AEKwhhz_ZlnfwIaFJ&opi=89978449)"
    Quizzes: "Quiz 4 | week 5| out 2/07 - due 2/14"


  - 7:
    Week: 7
    Dates: "2/17 - 2/21"
    Topics:
      - "Toolbox on Classification Algorithms"
      - "Toolbox on Word2Vec"

    Homework:
      - "**HW2 due 2/21**"
      - "HW3 out 2/21"



  - 8:
    Week: 8
    Dates: "2/24 - 2/28"
    Topics:
      - "CNN"
      - "RNN"
      - "Toolbox on CNN For Text Classification"
    Quizzes: "Quiz 5 | week 6 and week 7| out 2/21 - due 2/28"
    Readings:
      - "[CNN Live Demo](https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html);"
      - "[A guide to an efficient way to build CNN and optimize its hyper-parameters](https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-ii-hyper-parameter-42efca01e5d7);"
      - "[Back Propagation in CNN](https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/);"
      - "[Transfer learning in CNN](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a);"


  - 9:
    Week: 9
    Dates: "3/03 - 3/07"
    Topics:
      - "LSTM and GRU"
      - "LSTM + Attention (Focus on Attention mechanism)"
    Quizzes: "Quiz 6 | week 8| out 2/28 - due 3/07"

  - 10:
    Week: 10
    Dates: "3/10 - 3/14"
    Topics:
      - "Transformer models"
      - "Examples: BERT(Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer) "
 
    Quizzes: "Quiz 7 | week 9| out 3/07 - due 3/14"
    Readings:
      - "[Attention Is All You Need](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiPtd7Y9IWAAxU2JkQIHW1EDKIQFnoECA0QAQ&url=https%3A%2F%2Farxiv.org%2Fabs%2F1706.03762&usg=AOvVaw2ceXGQohV5Kx51VSkfkG08&opi=89978449);"
      - "[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwj3vITv9IWAAxUkOkQIHYjkApEQFnoECA0QAQ&url=https%3A%2F%2Farxiv.org%2Fabs%2F1810.04805&usg=AOvVaw14sm9MmA6c9pcfLHgrP9Pk&opi=89978449);"
    Homework:
      - "**HW3 due 3/14**"
      - "**Note:** You may submit HW3 without penalty until **3/21**. Please note that this falls during Spring Break, so instructional support on Ed Discussion will be limited during that time."


  - 11:
    Week: 11
    Dates: "3/17 - 3/21"
    Topics:
      - "Spring Break"
    Homework:
      - "HW4 out 3/21"

  - 12:
    Week: 12
    Dates: "3/24 - 3/28"
    Topics:      
      - " Sequence Labelling: POS Tagging"
      - " Sequen1e Labelling: NER "
    Quizzes: "Quiz 8 | week 10| out 3/21 - due 3/28"

  - 13:
    Week: 13
    Dates: "3/31 - 4/04"
    Topics:
      - "Unsupervised Models"
      - "Topic Modeling (Latent Semantic Indexing, LDA (Latent Dirichlet Allocation)"
    Quizzes: "Quiz 9 | week 12| out 3/28 - due 4/04"


  - 14:
    Week: 14
    Dates: "4/07 - 4/11"
    Topics:
      - "Introduction to Generative AI"
      - "Prompt Engineering Techniques" 
      - "Retrieval Augmented Generation (RAG)"
    Quizzes: "Quiz 10 | week 13 | out 4/04 - due 4/11"

  - 15:
    Week: 15
    Dates: "4/14 - 4/18"
    Topics:
      - "Toolbox on Exploring LLMs"
    Homework:
      - "**HW4 due 4/18**"
      - "**Note:** You may submit HW4 without penalty until **4/22**."

    Quizzes: "Quiz 11 | week 14 | out 4/11 - due 4/18"



